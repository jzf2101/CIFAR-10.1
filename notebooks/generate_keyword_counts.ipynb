{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword Counts for Class Balanced Datasets\n",
    "\n",
    "This notebook determines the number of images for each keyword in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of cifar10 keywords 60000\n",
      "0.9959333333333333\n",
      "0.9959333333333333\n",
      "187 200\n",
      "190 200\n",
      "181 200\n",
      "195 200\n",
      "185 200\n",
      "188 200\n",
      "174 200\n",
      "182 200\n",
      "178 200\n",
      "185 200\n",
      "airplane, 200\n",
      "automobile, 200\n",
      "bird, 200\n",
      "cat, 200\n",
      "deer, 200\n",
      "dog, 200\n",
      "frog, 200\n",
      "horse, 200\n",
      "ship, 200\n",
      "truck, 200\n",
      "ERROR cruiser appears for automobile and ship\n",
      "ERROR cruiser appears for ship and automobile\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "from collections import Counter\n",
    "import sys\n",
    "import os\n",
    "\n",
    "repo_root = os.path.join(os.getcwd(), '../code')\n",
    "sys.path.append(repo_root)\n",
    "import utils\n",
    "import cifar10\n",
    "\n",
    "version = '7'\n",
    "\n",
    "with open('../other_data/cifar10_keywords_unique_v{}.json'.format(version)) as f:\n",
    "    cifar10_keywords = json.load(f)\n",
    "\n",
    "cifar = cifar10.CIFAR10Data('../other_data/cifar10')\n",
    "\n",
    "    \n",
    "class_names = utils.cifar10_label_names\n",
    "\n",
    "print('Length of cifar10 keywords {}'.format(len(cifar10_keywords)))\n",
    "\n",
    "def compute_top_k_keywords_per_class(cifar10_keywords, k):\n",
    "    keywords_per_class = {}\n",
    "    \n",
    "    for ii, entry in enumerate(cifar10_keywords):\n",
    "        cur_keyword = entry['nn_keyword']      \n",
    "        cur_label  = class_names[cifar.all_labels[ii]]\n",
    "        if not cur_label in keywords_per_class:\n",
    "            keywords_per_class[cur_label] = {}\n",
    "        if not cur_keyword in keywords_per_class[cur_label]:\n",
    "            keywords_per_class[cur_label][cur_keyword] = 0\n",
    "        keywords_per_class[cur_label][cur_keyword] +=1\n",
    "    \n",
    "    top_k_keywords_per_class = {}\n",
    "    total_keyword_counts_per_class = {}\n",
    "    for label, keyword_dict in keywords_per_class.items():\n",
    "        sorted_keywords = sorted(keyword_dict.items(), key=lambda x:x[1], reverse=True)\n",
    "        total_keyword_counts_per_class[label] = 0\n",
    "        for _, v in keyword_dict.items():\n",
    "            total_keyword_counts_per_class[label] += v\n",
    "        top_k_keyword_dict = {}\n",
    "        for keyword, count in sorted_keywords[:k]:\n",
    "            top_k_keyword_dict[keyword] = count\n",
    "        top_k_keywords_per_class[label] = top_k_keyword_dict\n",
    "\n",
    "    return top_k_keywords_per_class, total_keyword_counts_per_class\n",
    "   \n",
    "       \n",
    "    \n",
    "def compute_new_keyword_counts(new_dataset_size, top_k_keywords_per_class, \n",
    "                               total_keyword_counts_per_class, use_total_keyword_counts=False):\n",
    "    '''\n",
    "    top_k_keywords_per_class: dictionary from class to another dictionary. The\n",
    "    inner dictionary goes from keyword to keyword count in CIFAR10\n",
    "    '''\n",
    "    assert new_dataset_size % 10 == 0\n",
    "    num_per_class = int(new_dataset_size / 10)\n",
    "    result = {}\n",
    "    for label in class_names:\n",
    "        new_keyword_frequencies = {}\n",
    "        new_keyword_rounding_gap = {}\n",
    "        new_keyword_count = {}\n",
    "        total_count = 0\n",
    "        total_keyword_count = 0\n",
    "        for _, value in top_k_keywords_per_class[label].items():\n",
    "            total_keyword_count += value\n",
    "        if use_total_keyword_counts:\n",
    "            cur_keyword_count = total_keyword_counts_per_class[label]\n",
    "        else:\n",
    "            cur_keyword_count = total_keyword_count\n",
    "\n",
    "        for keyword, value in top_k_keywords_per_class[label].items():\n",
    "            frequency = num_per_class * (value / cur_keyword_count)\n",
    "            new_keyword_frequencies[keyword] = frequency\n",
    "            new_keyword_rounding_gap[keyword] = frequency - math.floor(frequency)\n",
    "            new_keyword_count[keyword] = int(math.floor(frequency))\n",
    "            total_count += new_keyword_count[keyword]\n",
    "        print(total_count, num_per_class)\n",
    "        assert total_count <= num_per_class\n",
    "        assert total_count >= num_per_class - len(top_k_keywords_per_class[label])\n",
    "        # sort the keywords by the rounding gap\n",
    "        new_keyword_rounding_gap_sorted = sorted(new_keyword_rounding_gap.items(),\n",
    "                                                 key=lambda x:x[1], reverse=True)\n",
    "        for ii in range(num_per_class - total_count):\n",
    "            keyword = new_keyword_rounding_gap_sorted[ii][0]\n",
    "            new_keyword_count[keyword] += 1\n",
    "        new_keyword_count_final = {}\n",
    "        for key, value in new_keyword_count.items():\n",
    "            if value > 0:\n",
    "                new_keyword_count_final[key] = value\n",
    "        result[label] = new_keyword_count_final\n",
    "    return result\n",
    "    \n",
    "top_k = 50\n",
    "    \n",
    "top_k_keywords_per_class, total_keyword_counts_per_class = compute_top_k_keywords_per_class(cifar10_keywords, top_k)\n",
    "\n",
    "top_k_sum = 0\n",
    "for _, val in top_k_keywords_per_class.items():\n",
    "    for keyword in val:\n",
    "        top_k_sum += val[keyword]\n",
    "\n",
    "total_sum = 0\n",
    "for _, val in total_keyword_counts_per_class.items():\n",
    "    total_sum += val\n",
    "\n",
    "print(top_k_sum / total_sum)\n",
    "print(top_k_sum / 60000)\n",
    "\n",
    "\n",
    "result = compute_new_keyword_counts(2000, top_k_keywords_per_class, total_keyword_counts_per_class)\n",
    "\n",
    "with open('../other_data/keyword_counts_v{}.json'.format(version), 'w') as f:\n",
    "    json.dump(result, f, indent=2)\n",
    "\n",
    "for label in result:\n",
    "    total_count = 0\n",
    "    for keyword in result[label]:\n",
    "        total_count += result[label][keyword]\n",
    "    print('{}, {}'.format( label, total_count))\n",
    "    \n",
    "for label in result:\n",
    "    for keyword in result[label]:\n",
    "        for label2 in result:\n",
    "            if label == label2:\n",
    "                continue\n",
    "            if keyword in result[label2]:\n",
    "                print('ERROR {} appears for {} and {}'.format(keyword, label, label2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check that we have enough labeled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stealth_bomber 19 20\n",
      "attack_aircraft 14 13 WARNING, TOO MANY OLD\n",
      "dive_bomber 11 10 WARNING, TOO MANY OLD\n",
      "twinjet 11 10 WARNING, TOO MANY OLD\n",
      "jumbojet 7 6 WARNING, TOO MANY OLD\n",
      "multiengine_airplane 3 4\n",
      "plane 4 3 WARNING, TOO MANY OLD\n",
      "airplane 2 1 WARNING, TOO MANY OLD\n",
      "floatplane 2 1 WARNING, TOO MANY OLD\n",
      "aeroplane 0 1\n",
      "hangar_queen 0 1\n",
      "auto 17 16 WARNING, TOO MANY OLD\n",
      "wagon 11 8 WARNING, TOO MANY OLD\n",
      "taxi 4 3 WARNING, TOO MANY OLD\n",
      "compact 3 2 WARNING, TOO MANY OLD\n",
      "cruiser 3 2 WARNING, TOO MANY OLD\n",
      "ambulance 2 1 WARNING, TOO MANY OLD\n",
      "cab 2 1 WARNING, TOO MANY OLD\n",
      "funny_wagon 2 1 WARNING, TOO MANY OLD\n",
      "bird 17 18\n",
      "cassowary 18 17 WARNING, TOO MANY OLD\n",
      "passerine 10 11\n",
      "emu 11 10 WARNING, TOO MANY OLD\n",
      "struthio_camelus 11 10 WARNING, TOO MANY OLD\n",
      "pipit 10 9 WARNING, TOO MANY OLD\n",
      "dunnock 8 7 WARNING, TOO MANY OLD\n",
      "nandu 6 5 WARNING, TOO MANY OLD\n",
      "alauda_arvensis 6 5 WARNING, TOO MANY OLD\n",
      "dromaius_novaehollandiae 3 4\n",
      "anthus_pratensis 6 4 WARNING, TOO MANY OLD\n",
      "prunella_modularis 6 4 WARNING, TOO MANY OLD\n",
      "rhea_americana 5 4 WARNING, TOO MANY OLD\n",
      "lark 5 3 WARNING, TOO MANY OLD\n",
      "meadow_pipit 5 3 WARNING, TOO MANY OLD\n",
      "apteryx 3 2 WARNING, TOO MANY OLD\n",
      "bird_of_passage 0 2\n",
      "songbird 0 2\n",
      "flightless_bird 3 2 WARNING, TOO MANY OLD\n",
      "rhea 0 2\n",
      "cock 0 2\n",
      "hen 0 1\n",
      "skylark 0 1\n",
      "kiwi 0 1\n",
      "night_bird 0 1\n",
      "ratite 0 1\n",
      "emu_novaehollandiae 3 1 WARNING, TOO MANY OLD\n",
      "elephant_bird 0 1\n",
      "gamecock 0 1\n",
      "tabby_cat 36 37\n",
      "tabby 31 30 WARNING, TOO MANY OLD\n",
      "domestic_cat 27 28\n",
      "keyword felis_domesticus does not have enough tinyimage good indices\n",
      "felis_domesticus 11 12\n",
      "true_cat 10 9 WARNING, TOO MANY OLD\n",
      "elk 16 15 WARNING, TOO MANY OLD\n",
      "fallow_deer 13 15\n",
      "capreolus_capreolus 15 14 WARNING, TOO MANY OLD\n",
      "cervus_elaphus 13 12 WARNING, TOO MANY OLD\n",
      "muntjac 11 10 WARNING, TOO MANY OLD\n",
      "roe_deer 12 10 WARNING, TOO MANY OLD\n",
      "alces_alces 8 7 WARNING, TOO MANY OLD\n",
      "wapiti 8 7 WARNING, TOO MANY OLD\n",
      "american_elk 8 7 WARNING, TOO MANY OLD\n",
      "red_deer 7 6 WARNING, TOO MANY OLD\n",
      "rangifer_tarandus 5 6\n",
      "sika 5 4 WARNING, TOO MANY OLD\n",
      "caribou 5 4 WARNING, TOO MANY OLD\n",
      "rangifer_caribou 5 4 WARNING, TOO MANY OLD\n",
      "woodland_caribou 5 4 WARNING, TOO MANY OLD\n",
      "dama_dama 4 3 WARNING, TOO MANY OLD\n",
      "cervus_sika 4 3 WARNING, TOO MANY OLD\n",
      "stag 3 2 WARNING, TOO MANY OLD\n",
      "cervus_unicolor 0 2\n",
      "japanese_deer 0 2\n",
      "musk_deer 0 2\n",
      "barren_ground_caribou 0 1\n",
      "reindeer 0 1\n",
      "european_elk 0 1\n",
      "brocket 0 1\n",
      "pekingese 25 26\n",
      "chihuahua 17 16 WARNING, TOO MANY OLD\n",
      "pekinese 14 13 WARNING, TOO MANY OLD\n",
      "mutt 10 9 WARNING, TOO MANY OLD\n",
      "maltese_dog 9 8 WARNING, TOO MANY OLD\n",
      "toy_dog 8 7 WARNING, TOO MANY OLD\n",
      "canis_familiaris 6 5 WARNING, TOO MANY OLD\n",
      "peke 6 5 WARNING, TOO MANY OLD\n",
      "king_charles_spaniel 4 3 WARNING, TOO MANY OLD\n",
      "english_toy_spaniel 7 2 WARNING, TOO MANY OLD\n",
      "feist 2 1 WARNING, TOO MANY OLD\n",
      "bufo_bufo 13 20\n",
      "bufo_viridis 12 11 WARNING, TOO MANY OLD\n",
      "bufo_americanus 10 9 WARNING, TOO MANY OLD\n",
      "toad 10 9 WARNING, TOO MANY OLD\n",
      "bufo_marinus 9 8 WARNING, TOO MANY OLD\n",
      "bullfrog 9 7 WARNING, TOO MANY OLD\n",
      "american_toad 9 6 WARNING, TOO MANY OLD\n",
      "rana_pipiens 7 5 WARNING, TOO MANY OLD\n",
      "western_toad 6 5 WARNING, TOO MANY OLD\n",
      "spring_frog 5 4 WARNING, TOO MANY OLD\n",
      "grass_frog 6 4 WARNING, TOO MANY OLD\n",
      "crapaud 4 3 WARNING, TOO MANY OLD\n",
      "bufo_calamita 4 3 WARNING, TOO MANY OLD\n",
      "bufo 10 3 WARNING, TOO MANY OLD\n",
      "alytes_obstetricans 4 3 WARNING, TOO MANY OLD\n",
      "true_frog 0 3\n",
      "texas_toad 0 3\n",
      "anuran 0 2\n",
      "barking_frog 0 2\n",
      "tailed_frog 0 2\n",
      "bufo_boreas 0 2\n",
      "natterjack 4 2 WARNING, TOO MANY OLD\n",
      "bufo_debilis 0 2\n",
      "southwestern_toad 0 2\n",
      "european_toad 0 1\n",
      "midwife_toad 0 1\n",
      "cascades_frog 0 1\n",
      "leptodactylus_pentadactylus 0 1\n",
      "yosemite_toad 0 1\n",
      "bufo_speciosus 0 1\n",
      "bufo_microscaphus 0 1\n",
      "leptodactylid 0 1\n",
      "rana_cascadae 0 1\n",
      "true_toad 0 1\n",
      "quarter_horse 15 16\n",
      "lippizaner 11 12\n",
      "appaloosa 10 9 WARNING, TOO MANY OLD\n",
      "dawn_horse 9 8 WARNING, TOO MANY OLD\n",
      "stallion 9 7 WARNING, TOO MANY OLD\n",
      "lippizan 10 7 WARNING, TOO MANY OLD\n",
      "walking_horse 6 5 WARNING, TOO MANY OLD\n",
      "cow_pony 3 2 WARNING, TOO MANY OLD\n",
      "female_horse 3 2 WARNING, TOO MANY OLD\n",
      "buckskin 3 2 WARNING, TOO MANY OLD\n",
      "american_saddle_horse 0 1\n",
      "plantation_walking_horse 0 1\n",
      "arab 0 1\n",
      "mare 0 1\n",
      "studhorse 0 1\n",
      "horse 2 1 WARNING, TOO MANY OLD\n",
      "prancer 0 1\n",
      "passenger_ship 16 17\n",
      "boat 13 14\n",
      "cargo_ship 8 10\n",
      "ship 7 8\n",
      "pilot_boat 7 6 WARNING, TOO MANY OLD\n",
      "pontoon 7 6 WARNING, TOO MANY OLD\n",
      "pleasure_boat 5 4 WARNING, TOO MANY OLD\n",
      "dredger 5 4 WARNING, TOO MANY OLD\n",
      "guard_boat 5 4 WARNING, TOO MANY OLD\n",
      "liberty_ship 4 3 WARNING, TOO MANY OLD\n",
      "scow 0 3\n",
      "motorboat 0 3\n",
      "houseboat 0 3\n",
      "tanker 4 3 WARNING, TOO MANY OLD\n",
      "containership 0 2\n",
      "iceboat 0 2\n",
      "icebreaker 0 2\n",
      "packet_boat 0 2\n",
      "tank_ship 0 2\n",
      "barge 0 2\n",
      "tugboat 0 2\n",
      "pleasure_craft 0 2\n",
      "ferryboat 0 2\n",
      "fireboat 0 2\n",
      "hydrofoil 0 1\n",
      "racing_boat 0 1\n",
      "supertanker 0 1\n",
      "ferry 0 1\n",
      "river_boat 0 1\n",
      "norfolk_wherry 0 1\n",
      "merchantman 0 1\n",
      "abandoned_ship 0 1\n",
      "minesweeper 0 1\n",
      "cruiser 3 1 WARNING, TOO MANY OLD\n",
      "tug 0 1\n",
      "rowboat 0 1\n",
      "trucking_rig 16 15 WARNING, TOO MANY OLD\n",
      "tipper_truck 13 14\n",
      "delivery_truck 13 12 WARNING, TOO MANY OLD\n",
      "fire_truck 12 11 WARNING, TOO MANY OLD\n",
      "moving_van 7 6 WARNING, TOO MANY OLD\n",
      "wrecker 6 5 WARNING, TOO MANY OLD\n",
      "trailer_truck 6 5 WARNING, TOO MANY OLD\n",
      "tipper 7 5 WARNING, TOO MANY OLD\n",
      "ladder_truck 6 5 WARNING, TOO MANY OLD\n",
      "tipper_lorry 5 4 WARNING, TOO MANY OLD\n",
      "semi 4 3 WARNING, TOO MANY OLD\n",
      "tow_truck 3 2 WARNING, TOO MANY OLD\n",
      "sound_truck 3 2 WARNING, TOO MANY OLD\n",
      "delivery_van 3 2 WARNING, TOO MANY OLD\n",
      "car_transporter 0 2\n",
      "tip_truck 0 2\n",
      "transporter 0 1\n",
      "pantechnicon 0 1\n",
      "tandem_trailer 0 1\n",
      "dustcart 0 1\n",
      "laundry_truck 0 1\n",
      "panel_truck 0 1\n",
      "rig 0 1\n",
      "103 96 1\n",
      "['felis_domesticus']\n"
     ]
    }
   ],
   "source": [
    "with open('../other_data/cifar10.1_v4_ti_indices_per_keyword.json', 'r') as f:\n",
    "    v4_indices = json.load(f)\n",
    "v4_count = {}\n",
    "for key, value in v4_indices.items():\n",
    "    v4_count[key] = len(value)\n",
    "\n",
    "with open('../other_data/tinyimage_good_indices_subselected_v{}.json'.format(version), 'r') as f:\n",
    "    tinyimage_good_indices = json.load(f)\n",
    "    \n",
    "with open('../other_data/blacklist_v{}.json'.format(version), 'r') as f:\n",
    "    blacklist = json.load(f)\n",
    "    \n",
    "for item in blacklist:\n",
    "    for keyword in tinyimage_good_indices:\n",
    "        if item in tinyimage_good_indices[keyword]:\n",
    "            tinyimage_good_indices[keyword].remove(item)\n",
    "\n",
    "\n",
    "num_total_new_keywords = 0\n",
    "num_total_warnings = 0\n",
    "num_total_new = 0\n",
    "new_keywords = []\n",
    "for label in result:\n",
    "    for keyword in result[label]:\n",
    "        count_new = result[label][keyword]\n",
    "        if keyword in v4_count:\n",
    "            count_old = v4_count[keyword]\n",
    "        else:\n",
    "            count_old = 0\n",
    "        if keyword not in tinyimage_good_indices:\n",
    "            print('keyword {} not in tinyimage good indices'.format(keyword))\n",
    "            num_total_new_keywords += 1\n",
    "            new_keywords.append(keyword)\n",
    "            assert count_old == 0\n",
    "        else:\n",
    "            if count_new > len(tinyimage_good_indices[keyword]):\n",
    "                print('keyword {} does not have enough tinyimage good indices'.format(keyword))\n",
    "                num_total_new_keywords += 1\n",
    "                new_keywords.append(keyword)\n",
    "            assert count_old <= len(tinyimage_good_indices[keyword])\n",
    "        if count_new != count_old:\n",
    "            if count_old > count_new:\n",
    "                num_total_warnings += 1\n",
    "                print('{} {} {} WARNING, TOO MANY OLD'.format(keyword, count_old, count_new))\n",
    "            else:\n",
    "                num_total_new += 1\n",
    "                print('{} {} {}'.format(keyword, count_old, count_new))\n",
    "print(num_total_warnings, num_total_new, num_total_new_keywords)\n",
    "print(new_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
