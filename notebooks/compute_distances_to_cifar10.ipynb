{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import io\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "import numpy as np\n",
    "import pywren\n",
    "\n",
    "repo_root = os.path.join(os.getcwd(), '../code')\n",
    "sys.path.append(repo_root)\n",
    "\n",
    "import cifar10\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_exists(bucket, key):\n",
    "    '''Return true if a key exists in s3 bucket'''\n",
    "    client = boto3.client('s3')\n",
    "    try:\n",
    "        obj = client.head_object(Bucket=bucket, Key=key)\n",
    "        return True\n",
    "    except botocore.exceptions.ClientError as exc:\n",
    "        if exc.response['Error']['Code'] != '404':\n",
    "            raise\n",
    "        return False\n",
    "\n",
    "def make_key(batch_index):\n",
    "    return 'tinyimages_nearest_neighbor_tmp/ti_nn_batch_{}'.format(batch_index)\n",
    "\n",
    "def get_data_for_key(bucket, key):\n",
    "    client = boto3.client('s3')\n",
    "    pickle_bytes = client.get_object(Bucket=bucket, Key=key)['Body'].read()\n",
    "    return pickle.loads(pickle_bytes)\n",
    "\n",
    "def store_data_for_key(bucket, key, obj):\n",
    "    client = boto3.client('s3')\n",
    "    tmp = pickle.dumps(obj)\n",
    "    client.put_object(Bucket=bucket, Key=key, Body=tmp)\n",
    "    \n",
    "def make_distance_matrix(X_test, X_train):\n",
    "    D = X_test.dot(X_train.T)\n",
    "    D *= -2\n",
    "    D += (np.linalg.norm(X_train, axis=1)**2)[:, np.newaxis].T\n",
    "    D += (np.linalg.norm(X_test, axis=1)**2)[:, np.newaxis]\n",
    "    return D\n",
    "\n",
    "def compute_nearest_neighbors_batch(b_tuple):\n",
    "    batch_index, b = b_tuple\n",
    "    s3 = boto3.client('s3')\n",
    "    # Replace this with a bucket you have write access to and that contains the relevant files (see below)\n",
    "    bucket = 'cifar-10-1'\n",
    "    \n",
    "    if key_exists(bucket, make_key(batch_index)):\n",
    "        return get_data_for_key(bucket, make_key(batch_index))\n",
    "    \n",
    "    if len(b) == 0:\n",
    "        res = []\n",
    "        store_data_for_key(bucket, make_key(batch_index), res)\n",
    "        return res\n",
    "    \n",
    "    if not os.path.exists('data/cifar10'):\n",
    "        print('Downloading CIFAR10 data ...')\n",
    "        os.mkdir('data')\n",
    "        os.mkdir('data/cifar10')\n",
    "        s3.download_file(bucket, 'cifar10/data_batch_1', 'data/cifar10/data_batch_1')\n",
    "        s3.download_file(bucket, 'cifar10/data_batch_2', 'data/cifar10/data_batch_2')\n",
    "        s3.download_file(bucket, 'cifar10/data_batch_3', 'data/cifar10/data_batch_3')\n",
    "        s3.download_file(bucket, 'cifar10/data_batch_4', 'data/cifar10/data_batch_4')\n",
    "        s3.download_file(bucket, 'cifar10/data_batch_5', 'data/cifar10/data_batch_5')\n",
    "        s3.download_file(bucket, 'cifar10/batches.meta', 'data/cifar10/batches.meta')\n",
    "        s3.download_file(bucket, 'cifar10/test_batch', 'data/cifar10/test_batch')\n",
    "    cifar = cifar10.CIFAR10Data('data/cifar10')\n",
    "    cifar_images = np.reshape(cifar.all_images, [60000, -1])\n",
    "    dim = 32 * 32 * 3\n",
    "    assert cifar_images.shape[1] == dim\n",
    "    cifar_images = cifar_images.astype(np.float64)\n",
    "        \n",
    "    pickle_bytes = s3.get_object(Bucket=bucket, Key='tinyimage_subset_data.pickle')['Body'].read()\n",
    "    tinyimages = pickle.loads(pickle_bytes)\n",
    "    \n",
    "    bsize = len(b)\n",
    "    batch_images_list = []\n",
    "    for index in b:\n",
    "        tmp_vec = np.reshape(tinyimages[index], [-1])\n",
    "        assert tmp_vec.shape == (dim,)\n",
    "        batch_images_list.append(tmp_vec)\n",
    "    batch_images = np.vstack(batch_images_list).astype(np.float64)\n",
    "    assert batch_images.shape == (bsize, dim)\n",
    "    \n",
    "    dst_matrix = np.sqrt(make_distance_matrix(batch_images, cifar_images))\n",
    "    assert dst_matrix.shape == (bsize, 60000)\n",
    "    \n",
    "    res = []\n",
    "    k = 10\n",
    "    for ii, index in enumerate(b):\n",
    "        cur_dsts = dst_matrix[ii, :]\n",
    "        top_indices = np.argsort(cur_dsts)\n",
    "        cur_res = []\n",
    "        for jj in range(k):\n",
    "            cur_index = top_indices[jj]\n",
    "            cur_res.append((int(cur_index), float(cur_dsts[cur_index])))\n",
    "        res.append((index, cur_res))\n",
    "\n",
    "    store_data_for_key(bucket, make_key(batch_index), res)\n",
    "    return res\n",
    "\n",
    "def split_into_batches(inputs, num_batches):\n",
    "    batch_size = int(math.ceil(len(inputs) / num_batches))\n",
    "    print('Batch size: {}'.format(batch_size))\n",
    "    cur_start = 0\n",
    "    result = []\n",
    "    for ii in range(num_batches):\n",
    "        cur_end = cur_start + batch_size\n",
    "        cur_end = min(cur_end, len(inputs))\n",
    "        result.append(inputs[cur_start : cur_end])\n",
    "        cur_start += batch_size\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading indices from file /Users/ludwig/research/deep_learning/tinyimages/repo/data/tinyimage_subset_indices.json\n",
      "Loading image data from file /Users/ludwig/research/deep_learning/tinyimages/repo/data/tinyimage_subset_data.pickle\n"
     ]
    }
   ],
   "source": [
    "# Also change the version in compute_nearest_neighbors_batch above\n",
    "version_string = ''\n",
    "ti_by_kw, _ = utils.load_tinyimage_subset(version_string=version_string)\n",
    "\n",
    "img_indices = []\n",
    "for kw in ti_by_kw:\n",
    "    for item in ti_by_kw[kw]:\n",
    "        img_indices.append(item['tinyimage_index'])\n",
    "img_indices = sorted(img_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "589711"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 590\n"
     ]
    }
   ],
   "source": [
    "num_to_try = 589711\n",
    "num_batches = 1000\n",
    "#num_to_try = 1000\n",
    "#num_batches = 100\n",
    "\n",
    "keys = img_indices[:num_to_try]\n",
    "\n",
    "input_data_batches = []\n",
    "for ii, batch in enumerate(split_into_batches(keys, num_batches)):\n",
    "    input_data_batches.append((ii, batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwex = pywren.standalone_executor(job_max_runtime=999999)\n",
    "futures = pwex.map(compute_nearest_neighbors_batch, input_data_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in futures:\n",
    "    try:\n",
    "        f.result()\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pywren.get_all_results(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 1000 batches of results\n"
     ]
    }
   ],
   "source": [
    "print('Collected {} batches of results'.format(len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = {}\n",
    "for b in results:\n",
    "    for r in b:\n",
    "        res_dict[r[0]] = r[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 589711 total top-k nearest neighbors\n"
     ]
    }
   ],
   "source": [
    "print('Collected {} total top-k nearest neighbors'.format(len(res_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to tinyimage_cifar10_distances_full.json\n"
     ]
    }
   ],
   "source": [
    "filename = 'tinyimage_cifar10_distances_full.json'\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(res_dict, f, indent=2)\n",
    "print('Saved to {}'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11991, 2221.019360563973),\n",
       " (28387, 2264.6964476503263),\n",
       " (47852, 2273.062691612351),\n",
       " (39223, 2278.320653463862),\n",
       " (33869, 2296.747918253111),\n",
       " (9199, 2304.886765114505),\n",
       " (6518, 2305.2984622386753),\n",
       " (37146, 2307.6037354797277),\n",
       " (33061, 2312.686533017394),\n",
       " (29811, 2328.9849720425436)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dict[69341]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected answer for index 69341\n",
    "[(11991, 2221.019360563973),\n",
    " (28387, 2264.6964476503263),\n",
    " (47852, 2273.062691612351),\n",
    " (39223, 2278.320653463862),\n",
    " (33869, 2296.747918253111),\n",
    " (9199, 2304.886765114505),\n",
    " (6518, 2305.2984622386753),\n",
    " (37146, 2307.6037354797277),\n",
    " (33061, 2312.686533017394),\n",
    " (29811, 2328.9849720425436)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
