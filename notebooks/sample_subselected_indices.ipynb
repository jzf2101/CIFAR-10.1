{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample new labeled images for the class-balanced test sets\n",
    "\n",
    "Samples the subselected and labeled TinyImages indicies to create a class-balanced new test set.\n",
    "\n",
    "The script requires the following files from s3 in the `other_data` directory:\n",
    "* `tinyimage_large_dst_images_v6.1.json`\n",
    "* `tinyimage_large_dst_image_data_v6.1.pickle`\n",
    "\n",
    "These files can be downloaded with `other_data/download.py --all`.\n",
    "\n",
    "Smaller files required that are checked in to the repo:\n",
    "* `tinyimage_good_indices_subselected_v{}.json`\n",
    "* `blacklist_v{}.json`\n",
    "* `keywords_v{}.json`\n",
    "\n",
    "In addition, CIFAR-10 dataset should be downloaded in `other_data/cifar10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import io\n",
    "import json\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import widgets\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import tqdm\n",
    "\n",
    "repo_root = os.path.join(os.getcwd(), '../code')\n",
    "sys.path.append(repo_root)\n",
    "\n",
    "import cifar10\n",
    "import utils\n",
    "\n",
    "cifar = cifar10.CIFAR10Data('../other_data/cifar10')\n",
    "cifar_labels = cifar.all_labels\n",
    "\n",
    "version = '7'\n",
    "\n",
    "# Both v6 and v7 currently use the v6.1 image files\n",
    "with open('../other_data/tinyimage_large_dst_images_v6.1.json', 'r') as f:\n",
    "    all_new_imgs = json.load(f)\n",
    "with open('../other_data/tinyimage_large_dst_image_data_v6.1.pickle', 'rb') as f:\n",
    "    img_data = pickle.load(f)\n",
    "with open('../other_data/tinyimage_good_indices_subselected_v{}.json'.format(version), 'r') as f:\n",
    "    tinyimage_good_indices = json.load(f)\n",
    "with open('../other_data/keyword_counts_v{}.json'.format(version), 'r') as f:\n",
    "    keyword_counts_per_class = json.load(f)\n",
    "# Blacklist contains images that are near-duplicates in CIFAR-10\n",
    "with open('../other_data/blacklist_v{}.json'.format(version), 'r') as f:\n",
    "    blacklist = json.load(f)\n",
    "\n",
    "# Remove if the idx is on the blacklist \n",
    "# (the blacklist mostly contains near duplicates with CIFAR-10)\n",
    "for item in blacklist:\n",
    "    for keyword in tinyimage_good_indices:\n",
    "        if item in tinyimage_good_indices[keyword]:\n",
    "            tinyimage_good_indices[keyword].remove(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(670725112)\n",
    "dataset_size = 2000\n",
    "new_data = np.empty((dataset_size, 32,32,3), float)\n",
    "new_labels = np.empty(dataset_size, int)\n",
    "\n",
    "# Disambiguates whether the cruiser indices belong to the automobile or ship class\n",
    "with open('../other_data/cruiser_good_indices.json', 'r') as f:\n",
    "    cruiser_good_indices = json.load(f)\n",
    "    \n",
    "# Both v6 and v7 use the v4 indices as a starting point\n",
    "with open('../other_data/cifar10.1_v4_ti_indices_per_keyword.json', 'r') as f:\n",
    "    v4_indices = json.load(f)\n",
    "    \n",
    "\n",
    "ii = 0\n",
    "tiny_image_map = []\n",
    "ti_indices = {}\n",
    "for label in keyword_counts_per_class:\n",
    "    ti_indices[label] = {}\n",
    "    for keyword in keyword_counts_per_class[label]:\n",
    "        if keyword == 'cruiser':\n",
    "            if label == \"ship\": \n",
    "                existing_indices = []\n",
    "            else:\n",
    "                existing_indices = v4_indices[keyword]\n",
    "        else:\n",
    "            if keyword in v4_indices:\n",
    "                existing_indices = v4_indices[keyword]\n",
    "            else:\n",
    "                existing_indices = []\n",
    "        ti_indices[label][keyword] = existing_indices\n",
    "        \n",
    "        count_new = keyword_counts_per_class[label][keyword]\n",
    "        if keyword in v4_indices:\n",
    "            count_old = len(existing_indices)\n",
    "        else:\n",
    "            count_old = 0\n",
    "        if count_new != count_old:\n",
    "            if count_old > count_new:\n",
    "                # Remove images if we have too many for this particular keyword\n",
    "                num_images_to_remove = count_old - count_new\n",
    "                assert len(existing_indices) >= num_images_to_remove\n",
    "                # Sample new indices to remove from existing indices\n",
    "                sampled_indices_to_remove = random.sample(existing_indices, num_images_to_remove)      \n",
    "                for item in sampled_indices_to_remove:\n",
    "                    ti_indices[label][keyword].remove(item)\n",
    "            else:\n",
    "                # Add images if we need more for this particular keyword\n",
    "                num_new_images = count_new - count_old\n",
    "                \n",
    "                # Determine the set of new labeled indices to sample from \n",
    "                if keyword == \"cruiser\":\n",
    "                    cur_good_indices = cruiser_good_indices[label]\n",
    "                else:\n",
    "                    cur_good_indices = tinyimage_good_indices[keyword]\n",
    "                if count_old == 0:\n",
    "                    # There are no existing old indices\n",
    "                    ti_good_indices = cur_good_indices\n",
    "                else:\n",
    "                    ti_good_indices = list(set(cur_good_indices) - set(existing_indices))\n",
    "                \n",
    "                # Sample new indices to add\n",
    "                ti_sampled_indices = random.sample(ti_good_indices, num_new_images)\n",
    "                for item in ti_sampled_indices:\n",
    "                    ti_indices[label][keyword].append(item)\n",
    "        # Get the images and labels corresponding to the sampled indices \n",
    "        for idx in ti_indices[label][keyword]:\n",
    "            tiny_image_map.append(idx)\n",
    "            new_data[ii] = img_data[idx]\n",
    "            new_labels[ii] = cifar.label_names.index(label)\n",
    "            ii = ii+1\n",
    "               \n",
    "with open('../other_data/cifar10.1_v{}_ti_indices_map.json'.format(version), 'w') as f:\n",
    "    json.dump(tiny_image_map, f, indent=2)\n",
    "np.save('../datasets/cifar10.1_v{}_data.npy'.format(version), new_data.astype(np.uint8))\n",
    "np.save('../datasets/cifar10.1_v{}_labels.npy'.format(version), new_labels.astype(np.int32))\n",
    "with open('../../tiny_images_2/data/tiny_image_map_v7.json'.format(version), 'w') as f:\n",
    "    json.dump(tiny_image_map, f, indent=2)\n",
    "np.save('../../tiny_images_2/data/new_cifar10_data_v7.npy'.format(version), new_data.astype(np.uint8))\n",
    "np.save('../../tiny_images_2/data/new_cifar10_labels_v7.npy'.format(version), new_labels.astype(np.int32))\n",
    "\n",
    "\n",
    "# Check that the dataset is class balanced\n",
    "label_counts = {}\n",
    "for i in range(10):\n",
    "    total_count = 0\n",
    "    for j in range(len(new_labels)):\n",
    "        if new_labels[j] == i:\n",
    "            total_count +=1\n",
    "    assert total_count == dataset_size / len(cifar.label_names)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
